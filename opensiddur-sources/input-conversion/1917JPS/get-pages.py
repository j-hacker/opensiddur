#!/usr/bin/env python
# get-pages.py for the JPS 1917 PDF extract project.
# Copyright 2013 Marc Stober and licensed under the GNU LGPL.

# Break the big XML file generated by PDFMiner (pdf2txt.py) 
# into sections of specific pages.
# Theoretically could do this using XSL but saxon throws out of memory exception.

from __future__ import print_function

import os.path
import re
import sys
import traceback

def get_pages(path, page_range):
	f = open(path, 'r')
	from_page, to_page = page_range
	page_pattern = re.compile('id="(\d+)"')
	ok = True

	for line in f:
		if line.strip().startswith('<page '):
			current_page = int(page_pattern.search(line).group(1))
			if current_page < from_page:
				ok = False
			else:
				if current_page > to_page:
					break # skip to end
				ok = True
		if ok:
			print(line, end='')

	f.close()
	# just print this rather than try to find last line of input file
	print('</pages>')

if __name__ == '__main__':
	try:
		page_range = [int(x) for x in sys.argv[1].split('-')]
		path = sys.argv[2]
		get_pages(path, page_range)
	except:
		script = os.path.split(sys.argv[0])[1]
		print('Usage: {0} <from>-<to> <path>'.format(script))
		print('Where path is output of pdf2txt.py (PDFMiner).')
		print('Example: {0} 10-15 mypdf.xml'.format(script))
		print('')
		traceback.print_exc()
		sys.exit(1) # help make fail

